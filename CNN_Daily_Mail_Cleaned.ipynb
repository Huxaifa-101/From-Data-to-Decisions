{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# \ud83d\udccc TEXT SUMMARIZATION PIPELINE\n",
        "# ===============================\n",
        "\n",
        "# --- Step 1: Setup ---\n",
        "!pip install -q datasets transformers spacy rouge-score evaluate\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "from datasets import load_dataset, Dataset\n",
        "from evaluate import load\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "\n",
        "# --- Step 2: Load & Clean Dataset ---\n",
        "print(\"\ud83d\udce5 Loading CNN/DailyMail dataset...\")\n",
        "ds = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
        "df = pd.DataFrame(ds['train'])\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'\\[[^]]*\\]', '', text)\n",
        "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9.?! ]+', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "df['cleaned_article'] = df['article'].apply(preprocess_text)\n",
        "\n",
        "# --- Step 3: Extractive Summarization (spaCy) ---\n",
        "print(\"\ud83d\udd0d Generating extractive summaries...\")\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extractive_summarization(article):\n",
        "    doc = nlp(article)\n",
        "    sentences = [sent.text for sent in doc.sents]\n",
        "    sentence_scores = {}\n",
        "    for sent in sentences:\n",
        "        for word in sent.split():\n",
        "            sentence_scores[word.lower()] = sentence_scores.get(word.lower(), 0) + 1\n",
        "    ranked = sorted(sentences, key=lambda s: sum(sentence_scores.get(w.lower(), 0) for w in s.split()), reverse=True)\n",
        "    return \" \".join(ranked[:3])\n",
        "\n",
        "tqdm.pandas()\n",
        "N = 100\n",
        "df_subset = df.head(N).copy()\n",
        "df_subset['extractive_summary'] = df_subset['cleaned_article'].progress_apply(extractive_summarization)\n",
        "\n",
        "# --- Step 4: Abstractive Summarization (T5) ---\n",
        "print(\"\ud83e\udd16 Generating abstractive summaries using T5...\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "def abstractive_summarization(article):\n",
        "    inputs = tokenizer.encode(\"summarize: \" + article, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = model.generate(inputs, max_length=50, min_length=10, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "df_subset['abstractive_summary'] = df_subset['cleaned_article'].progress_apply(abstractive_summarization)\n",
        "\n",
        "# --- Step 5: Evaluate with ROUGE ---\n",
        "print(\"\ud83d\udcca Evaluating summaries using ROUGE...\")\n",
        "rouge = load(\"rouge\")\n",
        "results = rouge.compute(predictions=df_subset['abstractive_summary'], references=df_subset['highlights'], use_stemmer=True)\n",
        "\n",
        "for k, v in results.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# --- Step 6: Save Output ---\n",
        "df_subset.to_csv(\"summarization_output.csv\", index=False)\n",
        "print(\"\ud83d\udcbe Output saved to summarization_output.csv\")\n",
        "\n",
        "# --- Step 7: Fine-tune T5 on Subset ---\n",
        "print(\"\ud83c\udf93 Fine-tuning T5 model...\")\n",
        "fine_tune_df = df_subset[['cleaned_article', 'highlights']].rename(columns={\n",
        "    'cleaned_article': 'input_text',\n",
        "    'highlights': 'target_text'\n",
        "})\n",
        "dataset = Dataset.from_pandas(fine_tune_df)\n",
        "\n",
        "max_input_length = 512\n",
        "max_target_length = 64\n",
        "\n",
        "def tokenize_data(example):\n",
        "    inputs = tokenizer(\"summarize: \" + example[\"input_text\"], truncation=True, padding=\"max_length\", max_length=max_input_length)\n",
        "    targets = tokenizer(example[\"target_text\"], truncation=True, padding=\"max_length\", max_length=max_target_length)\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_data, batched=False)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./t5_finetuned_cnn\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=1,\n",
        "    logging_steps=50,\n",
        "    remove_unused_columns=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"./t5_finetuned_cnn\")\n",
        "tokenizer.save_pretrained(\"./t5_finetuned_cnn\")\n",
        "\n",
        "# --- Final Output ---\n",
        "print(\"\\n\u2705 TEXT SUMMARIZATION PIPELINE COMPLETE\")\n",
        "print(\"Saved model to ./t5_finetuned_cnn\")\n",
        "print(\"\\n\ud83d\udccc Sample Output:\")\n",
        "print(\"\\nOriginal:\\n\", df_subset['cleaned_article'][0][:500], \"...\")\n",
        "print(\"\\nExtractive Summary:\\n\", df_subset['extractive_summary'][0])\n",
        "print(\"\\nAbstractive Summary:\\n\", df_subset['abstractive_summary'][0])\n",
        "print(\"\\nReference Summary:\\n\", df_subset['highlights'][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6fa9ae1eedc74b36b3f0456944eea9d2",
            "aae61a72ab10436abb5e37d2b4138669",
            "0233d034ea314c53a30d87fa1f4f81ce",
            "b564d20c10f74efab3c3bf05dc184363",
            "507c742e4c6242189229ecabee2571dd",
            "8541b0c5fc3a489a86eb234f64cd9366",
            "3e8d3d6704a74fe1bd224784ac068d18",
            "696966d7f142459c8ff5f60a047497f7",
            "12add412ac254d128734d22038747b20",
            "b364a37ad2c2413ea096d73b920f31fa",
            "35b3371136bb4b8f86782e52831b6aa3",
            "352f35b16bd343c0aded52f733e7ad0b",
            "f9665d0a40274f58834841f914b219a3",
            "49e06390238140cc9496cb2731811125",
            "9e8f2197cdfc4251b4ab99193a574fa6",
            "7c3c1bad126846b29a78d2d3f86f0a23",
            "f1ce27ffa84a46509d4c8c4e3e8a2929",
            "b4c0cb3b4fd94efba2a3987b6143b649",
            "f25e6188981e477080de00c0996d6330",
            "461bc84037f7476d8c683ad6a1ad807c",
            "faabfbbae14a463da470709d2a4b0865",
            "6bc5bf651c5d476bbb961a1159b2e8a2",
            "d0df90fe4a7c42fb883d18f6aa6938df",
            "9e9c4fae03c64ec48a18044c30a8db32",
            "fbd1340e94b24c5baa033185497fdac3",
            "78dbbea2d1f24a4bbd05cf2640570ee2",
            "94027da3278a4286bcbf70b0c9a63fab",
            "8ede4b45f3cb423ebacc87fb9d5daf5c",
            "06c97d3e6a1b458aab11040aa11dfa6e",
            "51ea2344664f47f8b03b4541b5d507f1",
            "8b577d1c78284d9d87e01c7a3c3a67ed",
            "81e8f6467cee40cf945841ad0600c5e5",
            "81d0370e81064165a1855238cebbc421",
            "3ab295db640d4bda8b28980008e8ccbb",
            "cc4326b58ad74d9081c6522c15ef959e",
            "42c1277bf2cf4a569c613985a7eb4cde",
            "b77b685a8e4d487b8d4d983fc8b2ba63",
            "b13ee6caddae43419d1410040d9d5568",
            "3e28d08925c84b24814299d03947682a",
            "3ff8e3a4d4154442ab4c1053488954aa",
            "b5adeb6cadbd436e8a99d85ddb9840ea",
            "863ba28fba79476386f4e78f29f45ca4",
            "fe0c24c17800422eae8f14bfeddf1f69",
            "d1b57180044042c3bfde501b94471759",
            "a9d61474860842a6919f9b1a05e2ae57",
            "a1b9475e9b6e432fb4b6cf8925477d09",
            "87358365be14454a803f742842501173",
            "86ae08e96b2b4601a8b021d084dd38a1",
            "dfd303706c3b4da88672ab844b3cfb37",
            "3cab5d5eaf5943ee8fa1b93da315d25e",
            "01772303036049be9de679badfa03952",
            "2b8b96952ed846e0af1310365d73e494",
            "49100fe0f87b4887baf0ef5ed577ec39",
            "cb7ee28eba984753a9094901e35b7638",
            "90ffedbe25ed42018dfa9aee5f2e107f",
            "b48dbd31793340828c82f18eab1bb9b0",
            "400a3ac6b55041efb9e30a083839aab5",
            "66ead5622dd14ee0ada42ca2a5225cf6",
            "8b377e72f7e349f8ae9010534ba2f835",
            "ce6c5aa70ea34554a89b6a21584d1141",
            "75e08c2bdbae4eeb856ce43fa4d5d053",
            "80313c29c7254ea8b9cba3b7b4a3b46a",
            "924b420bb4f645d89589bdab88f3c63b",
            "288fbb19a5b34d31b960cb4872ea7229",
            "3046b7cd4a674806b6bf89a5b05d9c08",
            "0fda4f27b43b4f15b24fcc8392aea324",
            "8bc5252621e54a828209ab309a798032",
            "f6b5890bcb9d4ffd82125e238dd0bb7b",
            "f247811a25e84860b7370fb9bd1c9b52",
            "c25c5e04bf7a4b82892814761f471956",
            "5bb0c61bf90d4461bdacbb9a01c01a41",
            "fdae32ce8c0c47038c49c02a1830358f",
            "8f7dca72327d4d09b7476eb5bfc47a9a",
            "656a6a7aa0904b6d898527777a56cb93",
            "f61291e98dbb4d02b5ec0c3ebb6ae9d8",
            "c559c15143c448d7b02a0d1bbccb46c3",
            "71f36952f4f44cdcac91f000d8f39d0f",
            "934bc3d5ebea4bb7b6e77184eebad582",
            "852fad391a6e4784814f053fba3c63cb",
            "ce5887aec45c4afba619829fd4c839dd",
            "c44b086507a348d396640c8bd47e4f85",
            "a23f987c21a4493b9e827004a2de6954",
            "b24ca4fc05734d40945340b881e77430",
            "49802963c8384606a46d017c010890fc",
            "a590e6996fe24d9abe944e0b541bc928",
            "9d61afc647f7401782b61b040720a862",
            "fae962cdc20b4d9299549a64486f55f8",
            "34b2fcee0752497b84335f4b5a0db2ee",
            "bd55a877beb7492ebd6e11e82340519c",
            "30384842b0c244d5b6773d2b2ddbe79c",
            "7d22a67072364e46901511d4bb1c27ac",
            "56260e9905254e199f61128b8622b4e4",
            "73777e08a42b4e36aa25c9340b8039eb",
            "1ff012d31f974783851bb252fa1d8127",
            "3404478329e84790b786590db98b32ca",
            "34ff6043a21b4ad7988bb471f30c56b8",
            "835f015ff4524c49994d32f805fb96d3",
            "e302a11006d8435fbb8b106007667751",
            "037db13319c64599aae5aeff4135412e",
            "271a34e30db140f7b3d3c2e2d25b5806",
            "089e7df10e0d4f2394b676ebf712a336",
            "f60ef0084bef43da9b6c232550d6fcb0",
            "38c61c27aa6a40a48fdb53d93afd56ec",
            "2fc1f9f0e00141c9a64b7fe8eaa7ae42",
            "b854cf09ec7349e8acd483454d00c25c",
            "9f608a9aaba44552a2bab2dd36781846",
            "736228cef20744e18d0922aca7c15e65",
            "37b8ef1a0abe411aa9b3297c478f03f6",
            "cb5f3bdfc92c4b71a4490c940e3ab37a",
            "4610877c12104d3fba71cde81eb90b5c",
            "1ef42cb61b834fc1959ef3da4bd85f40",
            "c8803f9c99e240bcb54b102286a93049",
            "6e38bfe64f7a447b8ba08dd0fb165e1d",
            "9a57da2a9a1f4365b17f2362a7dbc8f5",
            "1097ac857eff43bb8963ffccdc2df9f4",
            "f3723d1af29542039a24ae64354e9e52",
            "993050db70df45fbb5649fd8a504a551",
            "9dcbf4e2b90b4e658d3a28cb6e31f5db",
            "e1f78ce357b24c678d69cdfdf57f240a",
            "c5df4538a3684939ab8a5e7e9e6c0589",
            "7109fac44f574e4ebd3de263e13946a2",
            "1cfc94df264744c6a80357e2e4e762ac",
            "7b57d2b008bc469e82e9bb12da41df94",
            "c12805b5521d461f9ea48b6bcd69eead",
            "f4ffe54d88f84d33855acf7012fce5b0",
            "67ffe8f5c41c48a8bfb3c2335ebd7d3a",
            "12bdd9ca82774fdb8fdac701db7c5007",
            "9d20ece3f80e4dab896ad6f77a253fe1",
            "03371c215a074a278839ad7565aecaf4",
            "3b86b46c361748a0a930e8e2d72e2f96",
            "5cfb3c8269524df88bc044817c479660",
            "1b69d9648cbd4e3a90765edc52b49aaa",
            "54a0cf253eb54036b0a43b56770e4dd3",
            "28daed4c128b403dba17d5cabd2d8f98",
            "d22287ef4a2f46089506778187240ff8",
            "5a11b546308147a6bcc497face6724c3",
            "dde8d96c30e540548be39398e9e1969b",
            "243e0ca61247474fa65c329f5cd97df6",
            "0194c21346b74b4fb0c390fe38e036d2",
            "66f05045daab41cabbe6b9850c99a238",
            "a83f6618f9a24c5ca86a72af495d7668",
            "48631614899c433399bde6bc055d6f5b",
            "1e1671c64beb4c4ba705fcb7343f96d0",
            "7ec68a4957074f8392bfcd9390e3fe84",
            "15beb328cb8d4bc8bb028297789013dc",
            "bc87cde713074fb1a235bc910d29e298",
            "63eac8d3fac24052a52674eed73dea87",
            "bb6367506f7344cfb2db638420695cb2",
            "01a9f89de6134f13a45293c6c2567914",
            "880dddd48d07450cbc0eaf2ad4050c5e",
            "21b43b685e0440c9b7a033ee2555121d",
            "887e1aa886234ec6b7975f4eb84dff6a",
            "f36c286cd8c548b0b6bfad519c99a2e1",
            "187558ed7af642e6bdb630f122a039b8"
          ]
        },
        "id": "lIFDOZ1BA0RY",
        "outputId": "c3a81ce8-3412-48e4-f857-b18566ca1ecd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[38;5;2m\u2714 Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m\u26a0 Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\ud83d\udce5 Loading CNN/DailyMail dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:  35%|###4      | 10.5M/30.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fa9ae1eedc74b36b3f0456944eea9d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "352f35b16bd343c0aded52f733e7ad0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0df90fe4a7c42fb883d18f6aa6938df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ab295db640d4bda8b28980008e8ccbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udd0d Generating extractive summaries...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9d61474860842a6919f9b1a05e2ae57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83e\udd16 Generating abstractive summaries using T5...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b48dbd31793340828c82f18eab1bb9b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bc5252621e54a828209ab309a798032"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "934bc3d5ebea4bb7b6e77184eebad582"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd55a877beb7492ebd6e11e82340519c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "271a34e30db140f7b3d3c2e2d25b5806"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ef42cb61b834fc1959ef3da4bd85f40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cfc94df264744c6a80357e2e4e762ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\ud83d\udcca Evaluating summaries using ROUGE...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54a0cf253eb54036b0a43b56770e4dd3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1: 0.2980\n",
            "rouge2: 0.0990\n",
            "rougeL: 0.2088\n",
            "rougeLsum: 0.2504\n",
            "\ud83d\udcbe Output saved to summarization_output.csv\n",
            "\ud83c\udf93 Fine-tuning T5 model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ec68a4957074f8392bfcd9390e3fe84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 03:44, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.733600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u2705 TEXT SUMMARIZATION PIPELINE COMPLETE\n",
            "Saved model to ./t5_finetuned_cnn\n",
            "\n",
            "\ud83d\udccc Sample Output:\n",
            "\n",
            "Original:\n",
            " LONDON England   Harry Potter star Daniel Radcliffe gains access to a reported 20 million  fortune as he turns 18 on Monday but he insists the money wont cast a spell on him. Daniel Radcliffe as Harry Potter in Harry Potter and the Order of the Phoenix To the disappointment of gossip columnists around the world the young actor says he has no plans to fritter his cash away on fast cars drink and celebrity parties. I dont plan to be one of those people who as soon as they turn 18 suddenly buy them ...\n",
            "\n",
            "Extractive Summary:\n",
            " Daniel Radcliffe as Harry Potter in Harry Potter and the Order of the Phoenix To the disappointment of gossip columnists around the world the young actor says he has no plans to fritter his cash away on fast cars drink and celebrity parties. His latest outing as the boy wizard in Harry Potter and the Order of the Phoenix is breaking records on both sides of the Atlantic and he will reprise the role in the last two films. At 18 Radcliffe will be able to gamble in a casino buy a drink in a pub or see the horror film Hostel Part II currently six places below his number one movie on the UK box office chart.\n",
            "\n",
            "Abstractive Summary:\n",
            " despite his growing fame and riches he says he is keeping his feet firmly on the ground. he has filmed a TV movie about author Rudyard Kipling and his son due for release later this year\n",
            "\n",
            "Reference Summary:\n",
            " Harry Potter star Daniel Radcliffe gets \u00a320M fortune as he turns 18 Monday .\n",
            "Young actor says he has no plans to fritter his cash away .\n",
            "Radcliffe's earnings from first five Potter films have been held in trust fund .\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}